# Lab01S01 - Coleta Inicial de 100 Repositórios

### Descrição
O objetivo desta fase é realizar a **coleta inicial de dados** sobre os 100 repositórios mais populares do GitHub, utilizando a API GraphQL da própria plataforma, a partir de um script desenvolvido em Python, sem uso de bibliotecas de terceiros que encapsulem essa função.

Os dados coletados já incluem todas as métricas necessárias para responder às questões de pesquisa propostas no enunciado do trabalho.

---

### Objetivos desta Etapa
- Implementar uma **consulta GraphQL** que recupere dados de 100 repositórios mais populares.
- Coletar todas as métricas necessárias para responder às RQs:
  - **RQ01:** Idade do repositório (calculada a partir da data de criação).
  - **RQ02:** Total de pull requests aceitas.
  - **RQ03:** Total de releases.
  - **RQ04:** Tempo até a última atualização (calculado a partir da data de última atualização).
  - **RQ05:** Linguagem primária.
  - **RQ06:** Percentual de issues fechadas (razão entre issues fechadas e total de issues).
- Armazenar os dados coletados em um arquivo JSON.
- Garantir que a requisição seja feita automaticamente via script próprio.

---

### Estrutura do Projeto

```
├── check_rate_limit.py     # Verifica o limite de requisições da API do GitHub
├── fetch_data.py           # Executa a consulta GraphQL e salva os dados coletados
├── query.graphql           # Consulta GraphQL com as métricas necessárias
├── repos_100.json          # Arquivo com dados de 100 repositórios mais populares
├── README.md               # Documentação da entrega
```

---

### Tecnologias Utilizadas
- **Python 3.8+**
- **API GraphQL do GitHub**
- **Biblioteca requests** para comunicação HTTP
- **JSON** para armazenamento de dados

---

### Configuração e Execução

#### 1. Pré-requisitos
- Python 3.8 ou superior instalado.
- Token de acesso pessoal do GitHub (PAT) com permissões de leitura em repositórios públicos.
- Biblioteca `requests` instalada:
```bash
pip install requests
```

#### 2. Definir variável de ambiente com o token
Linux/Mac:
```bash
export GITHUB_TOKEN="token_teste1"
```
Windows (PowerShell):
```powershell
setx GITHUB_TOKEN "token_teste1"
```

#### 3. Verificar limite de requisições
```bash
python check_rate_limit.py
```

#### 4. Executar coleta de dados
```bash
python fetch_data.py
```
O resultado será salvo em `repos_100.json`.

---

### Estrutura dos Dados Coletados
Exemplo de um registro no `repos_100.json`:
```json
{
  "name": "freeCodeCamp",
  "owner": { "login": "freeCodeCamp" },
  "stargazerCount": 425545,
  "primaryLanguage": { "name": "TypeScript" },
  "createdAt": "2014-12-24T17:49:19Z",
  "updatedAt": "2025-08-11T20:15:05Z",
  "pullRequests": { "totalCount": 25669 },
  "releases": { "totalCount": 0 },
  "issues": { "totalCount": 192 },
  "issuesClosed": { "totalCount": 19600 }
}
```

---

### Metodologia
1. Foi criada uma query GraphQL (`query.graphql`) contendo todas as métricas necessárias para responder às RQs definidas no enunciado.
2. Utilizou-se `fetch_data.py` para enviar requisições autenticadas à API do GitHub e salvar os dados no arquivo `repos_100.json`.
3. Antes da coleta, o script `check_rate_limit.py` permite verificar se o limite de requisições da API é suficiente para evitar bloqueios.
4. Todos os dados foram coletados de forma automática, sem uso de bibliotecas que encapsulem o acesso à API GraphQL.
